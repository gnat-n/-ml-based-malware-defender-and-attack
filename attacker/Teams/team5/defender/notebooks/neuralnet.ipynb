{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15166, 2382) (8970, 2382)\n",
      "(24136, 2382)\n"
     ]
    }
   ],
   "source": [
    "# Load Benign and Malware Dataset\n",
    "benign_dataset = pd.read_csv(\"../data/benign.csv\")\n",
    "malware_dataset = pd.read_csv(\"../data/malware.csv\")\n",
    "\n",
    "print(benign_dataset.shape, malware_dataset.shape)\n",
    "\n",
    "# Add Ground Truth Column\n",
    "benign_dataset[\"ground_truth\"] = 0\n",
    "malware_dataset[\"ground_truth\"] = 1\n",
    "\n",
    "# Combine the Two Datasets Shuffling the Rows\n",
    "combined_dataset = pd.concat([benign_dataset, malware_dataset], ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
    "combined_dataset.drop(combined_dataset.columns[0], axis=1, inplace=True)\n",
    "print(combined_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2372</th>\n",
       "      <th>2373</th>\n",
       "      <th>2374</th>\n",
       "      <th>2375</th>\n",
       "      <th>2376</th>\n",
       "      <th>2377</th>\n",
       "      <th>2378</th>\n",
       "      <th>2379</th>\n",
       "      <th>2380</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.420227</td>\n",
       "      <td>0.023071</td>\n",
       "      <td>0.018127</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>0.016357</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.011414</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.711814</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.466895</td>\n",
       "      <td>0.014331</td>\n",
       "      <td>0.027563</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.018799</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.688761</td>\n",
       "      <td>0.013916</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.006673</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.212820</td>\n",
       "      <td>0.030069</td>\n",
       "      <td>0.027375</td>\n",
       "      <td>0.013397</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.007031</td>\n",
       "      <td>0.024746</td>\n",
       "      <td>0.008395</td>\n",
       "      <td>0.009149</td>\n",
       "      <td>0.008813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2382 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.420227  0.023071  0.018127  0.005615  0.016357  0.005127  0.011414   \n",
       "1  0.711814  0.001104  0.001083  0.001049  0.001112  0.001120  0.001007   \n",
       "2  0.466895  0.014331  0.027563  0.005298  0.018799  0.002148  0.006836   \n",
       "3  0.688761  0.013916  0.007406  0.006673  0.003337  0.004354  0.008464   \n",
       "4  0.212820  0.030069  0.027375  0.013397  0.019600  0.007031  0.024746   \n",
       "\n",
       "          7         8         9  ...  2372  2373  2374  2375    2376  2377  \\\n",
       "0  0.005127  0.004517  0.003845  ...   0.0   0.0   0.0   8.0  8192.0   0.0   \n",
       "1  0.000967  0.001042  0.001055  ...   0.0   0.0   0.0   0.0     0.0   0.0   \n",
       "2  0.003101  0.002979  0.002148  ...   0.0   0.0   0.0   0.0     0.0   0.0   \n",
       "3  0.004028  0.004924  0.002360  ...   0.0   0.0   0.0   8.0  8192.0   0.0   \n",
       "4  0.008395  0.009149  0.008813  ...   0.0   0.0   0.0   8.0  8192.0   0.0   \n",
       "\n",
       "   2378  2379    2380  ground_truth  \n",
       "0   0.0  72.0  8200.0             0  \n",
       "1   0.0   0.0     0.0             1  \n",
       "2   0.0  72.0  8192.0             0  \n",
       "3   0.0  72.0  8200.0             0  \n",
       "4   0.0  72.0  8200.0             0  \n",
       "\n",
       "[5 rows x 2382 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24136, 2381) (24136,)\n"
     ]
    }
   ],
   "source": [
    "X = combined_dataset.drop(\"ground_truth\", axis=1)\n",
    "y = combined_dataset[\"ground_truth\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "explained_variance_ratio_cumulative = np.cumsum(explained_variance_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components to retain for 95% variance: 679\n"
     ]
    }
   ],
   "source": [
    "n_components = np.argmax(explained_variance_ratio_cumulative >= 0.95) + 1\n",
    "print(f\"Number of components to retain for 95% variance: {n_components}\")\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "lda = LDA(n_components=1)\n",
    "X_lda = lda.fit_transform(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jwonn\\miniconda3\\envs\\py36\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(19308, 14) (4828, 14)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = xgb_model.feature_importances_\n",
    "\n",
    "N = 14\n",
    "selected_feature_indices = np.argsort(feature_importances)[::-1][:N]\n",
    "selected_features = X.columns[selected_feature_indices]\n",
    "\n",
    "X_train_selected = X_train.iloc[:, selected_feature_indices]\n",
    "X_test_selected = X_test.iloc[:, selected_feature_indices]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "print(X_train_scaled.shape, X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Print the PyTorch version\n",
    "print(torch.__version__)\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalwareDetector(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MalwareDetector, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        out, _ = self.rnn(x)\n",
    "        last_output = out[:, -1, :]\n",
    "        out = self.fc(last_output)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train_scaled.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = 2\n",
    "model = MalwareDetector(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MalwareDetector(\n",
       "  (rnn): RNN(14, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = data.TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.0000, Train Accuracy: 96.86%, Train AUC: 0.9696, Test Loss: 0.0000, Test Accuracy: 97.66%, Test AUC: 0.9776\n",
      "Epoch 2/10, Train Loss: 0.0000, Train Accuracy: 98.26%, Train AUC: 0.9830, Test Loss: 0.0000, Test Accuracy: 98.07%, Test AUC: 0.9814\n",
      "Epoch 3/10, Train Loss: 0.0000, Train Accuracy: 98.50%, Train AUC: 0.9851, Test Loss: 0.0000, Test Accuracy: 98.59%, Test AUC: 0.9857\n",
      "Epoch 4/10, Train Loss: 0.0000, Train Accuracy: 98.76%, Train AUC: 0.9877, Test Loss: 0.0000, Test Accuracy: 98.70%, Test AUC: 0.9873\n",
      "Epoch 5/10, Train Loss: 0.0000, Train Accuracy: 99.00%, Train AUC: 0.9901, Test Loss: 0.0000, Test Accuracy: 98.94%, Test AUC: 0.9887\n",
      "Epoch 6/10, Train Loss: 0.0000, Train Accuracy: 99.06%, Train AUC: 0.9908, Test Loss: 0.0000, Test Accuracy: 98.96%, Test AUC: 0.9902\n",
      "Epoch 7/10, Train Loss: 0.0000, Train Accuracy: 99.13%, Train AUC: 0.9913, Test Loss: 0.0000, Test Accuracy: 99.19%, Test AUC: 0.9913\n",
      "Epoch 8/10, Train Loss: 0.0000, Train Accuracy: 99.23%, Train AUC: 0.9923, Test Loss: 0.0000, Test Accuracy: 99.21%, Test AUC: 0.9918\n",
      "Epoch 9/10, Train Loss: 0.0000, Train Accuracy: 99.31%, Train AUC: 0.9931, Test Loss: 0.0000, Test Accuracy: 99.32%, Test AUC: 0.9925\n",
      "Epoch 10/10, Train Loss: 0.0000, Train Accuracy: 99.37%, Train AUC: 0.9937, Test Loss: 0.0000, Test Accuracy: 99.30%, Test AUC: 0.9928\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "train_auc_scores = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "test_auc_scores = []\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    train_loss_sum = 0.0\n",
    "    num_correct_train = 0\n",
    "    num_samples_train = 0\n",
    "    y_true_train = []\n",
    "    y_pred_train = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        num_correct_train += (predictions == labels).sum().item()\n",
    "        num_samples_train += labels.size(0)\n",
    "        y_true_train.extend(labels.cpu().numpy())\n",
    "        y_pred_train.extend(predictions.cpu().numpy())\n",
    "\n",
    "    train_accuracy = num_correct_train / num_samples_train * 100\n",
    "    train_losses.append(train_loss_sum / num_samples_train)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    train_auc_score = roc_auc_score(y_true_train, y_pred_train, average=\"weighted\")\n",
    "    train_auc_scores.append(train_auc_score)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss_sum = 0.0\n",
    "    num_correct_test = 0\n",
    "    num_samples_test = 0\n",
    "    y_true_test = []\n",
    "    y_pred_test = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            num_correct_test += (predictions == labels).sum().item()\n",
    "            num_samples_test += labels.size(0)\n",
    "            y_true_test.extend(labels.cpu().numpy())\n",
    "            y_pred_test.extend(predictions.cpu().numpy())\n",
    "\n",
    "    test_accuracy = num_correct_test / num_samples_test * 100\n",
    "    test_losses.append(test_loss_sum / num_samples_test)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    test_auc_score = roc_auc_score(y_true_test, y_pred_test, average=\"weighted\")\n",
    "    test_auc_scores.append(test_auc_score)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accuracies[-1]:.2f}%, Train AUC: {train_auc_scores[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}, Test Accuracy: {test_accuracies[-1]:.2f}%, Test AUC: {test_auc_scores[-1]:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "torch.save(model.state_dict(), \"../models/malware_detector.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
